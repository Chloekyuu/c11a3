{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "J1grKKjV-nzO",
    "outputId": "2b07549d-7ba6-4e10-dd9d-b232e58d6d35"
   },
   "outputs": [],
   "source": [
    "# pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "0CQf65BS-nzT",
    "outputId": "37de0002-4906-4e99-a47f-609be2f2fade"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPlease install this specific version of resampy for librosa to work without errors.\\n'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Please install this specific version of resampy for librosa to work without errors.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "7FE1qM7n-nzU",
    "outputId": "02c7b706-8c9c-42b4-ed25-b98f7cd915de"
   },
   "outputs": [],
   "source": [
    "# pip install resampy==0.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "_hwFIUlFzTYw",
    "outputId": "9419a67b-5c1d-47e0-a7f5-ec9b9cad5bca"
   },
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "GWrZdqrp2E98"
   },
   "outputs": [],
   "source": [
    "emotions ={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrgQMSEU-nzZ"
   },
   "source": [
    "### Data for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "vSe0sBT12HgO"
   },
   "outputs": [],
   "source": [
    "def load_extract_features(data_path):\n",
    "\n",
    "    '''\n",
    "    load_extract_features() is a function that is used to load all the audio files one at a time, compute their features and return the features as well as the target values.\n",
    "\n",
    "    There are around 8-10 audio files which are corrupted. We hardcode zero values for such files in order to maintain consistency.\n",
    "\n",
    "    ['calm', 'happy'] emotion data is categorized into 'positive' and  ['angry', 'fearful'] into 'negative'\n",
    "\n",
    "    Returns:\n",
    "    1. Features\n",
    "    2. Binary Target Values\n",
    "    '''\n",
    "    final_features,target_emotions, binary_label = [],[], []\n",
    "    count = 0\n",
    "    \n",
    "    for i in glob.glob(data_path + \"/Actor_*/*.wav\"): #Loop to read every file.\n",
    "        \n",
    "        name = os.path.basename(i)\n",
    "        #We split the name of the file to understand the emotion associated with the file.\n",
    "        split = name.split(\"-\")\n",
    "        #We know that the third identifier is associated with the emotion of the audio file. Hence, we use [2] as it represents the third identifier.\n",
    "        emotion = emotions[split[2]]\n",
    "\n",
    "        #Below is the code to categorize the emotions into two classes to make this a binary problem.\n",
    "        if emotion in ['calm', 'happy']:\n",
    "            binary_label.append(0)\n",
    "        elif emotion in ['angry', 'fearful']:\n",
    "            binary_label.append(1)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        with soundfile.SoundFile(i) as audio:\n",
    "            waveform = audio.read(dtype=\"float32\")\n",
    "            sr = audio.samplerate\n",
    "            \n",
    "            #Below is the code to extract the Mel spectrogram features\n",
    "            #128 is the standard for machine learning applications using Mel spectrograms\n",
    "            m_feature = librosa.feature.melspectrogram(y=waveform, sr=sr, n_mels=128, fmax=sr / 2.0).T\n",
    "            melspectrogram = np.mean(m_feature,axis=0)\n",
    "            if melspectrogram.shape != (128,):\n",
    "                melspectrogram = np.zeros(128)\n",
    "            \n",
    "            #Below is the code to extract the chromagram features\n",
    "            stft_wave = librosa.stft(waveform)\n",
    "            stft = np.abs(stft_wave)\n",
    "            c_feature = librosa.feature.chroma_stft(S=stft, sr=sr).T\n",
    "            chromagram = np.mean(c_feature,axis=0)\n",
    "            \n",
    "            #12 is the number of pitch classes\n",
    "            if chromagram.shape != (12,):\n",
    "                chromagram = np.zeros(12)\n",
    "                \n",
    "            features=np.array([])\n",
    "            features=np.hstack((chromagram, melspectrogram))\n",
    "        \n",
    "            final_features.append(features)\n",
    "            target_emotions.append(emotion)\n",
    "            \n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                print(\"Processed Audio File Number: \", count)\n",
    "    \n",
    "    #We return the features and the binary target values.\n",
    "    return np.array(final_features), np.array(binary_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "aER6S-_k2a9H"
   },
   "outputs": [],
   "source": [
    "#Please change the path below to the path of the folder saved in your computer.\n",
    "# data_path = './Audio_Speech_Actors_01-24'\n",
    "# X, binary_label = load_extract_features(data_path)\n",
    "# print(X.shape)\n",
    "# print(binary_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('matrix.txt', X, delimiter = ',')  \n",
    "# np.savetxt('binary_label.txt',binary_label,delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 140)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "X = np.loadtxt(open(\"matrix.txt\",\"rb\"), delimiter=\",\", skiprows=0)\n",
    "binary_label = np.loadtxt(open(\"binary_label.txt\",\"rb\"), delimiter=\",\", skiprows=0)\n",
    "\n",
    "print(X.shape) #should be (768,140)\n",
    "print(binary_label.shape) # should be (768,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, binary_label, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(W, X, Y, l):\n",
    "    # calculate hinge loss\n",
    "    n_s = X.shape[0]\n",
    "    distances = 1 - Y * (np.dot(X, W))\n",
    "    distances[distances < 0] = 0  # equivalent to max(0, distance)\n",
    "    hinge_loss =  (np.sum(distances) / n_s)\n",
    "    # calculate cost\n",
    "    cost = l / 2 * np.dot(W, W) + hinge_loss \n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(W, X, Y,l):\n",
    "\n",
    "    distance = 1 - (Y * np.dot(X, W))\n",
    "    dw = np.zeros(len(W))\n",
    "\n",
    "    for ind, d in enumerate(distance):\n",
    "        if (ind == W.shape[0]):\n",
    "            if max(0, d) != 0:\n",
    "                di =  - ( Y[ind] * X[ind])\n",
    "        else:\n",
    "            if max(0, d) == 0:\n",
    "                di = l*W\n",
    "            else:\n",
    "                di = l*W - ( Y[ind] * X[ind])\n",
    "        dw += di\n",
    "\n",
    "    dw = dw/len(Y)  # average\n",
    "\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(X, Y, step, l,max_iter):\n",
    "    X_bia = np.c_[X, np.ones(X.shape[0])]   # Pad 1's for the bias term\n",
    "    new_Y = np.ones((Y.shape[0]))\n",
    "\n",
    "    for i in range (Y.shape[0]):\n",
    "        if Y[i] == 0:\n",
    "            new_Y[i] = -1\n",
    "\n",
    "    w = np.zeros(X_bia.shape[1])\n",
    "    count = 0\n",
    "    cost = compute_cost(w, X_bia, new_Y, l)\n",
    "    for i in range(max_iter):\n",
    "        grad = calculate_gradient(w, X_bia, new_Y, l)\n",
    "        new_w = w - step * grad\n",
    "        new_cost = compute_cost(new_w, X_bia, new_Y, l)\n",
    "        print(cost)\n",
    "        if (new_cost<cost):\n",
    "            w = new_w\n",
    "            cost = new_cost\n",
    "            count= count +1\n",
    "        else:\n",
    "            break\n",
    "    print(count)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_accuracy(W,X,Y):\n",
    "\n",
    "    X_bia = np.c_[X, np.ones(X.shape[0])]   # Pad 1's for the bias term\n",
    "    new_Y = np.ones((Y.shape[0]))\n",
    "\n",
    "    for i in range (Y.shape[0]):\n",
    "        if Y[i] == 0:\n",
    "            new_Y[i] = -1\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        yp = np.sign(np.dot(W, X_bia[i])) #model\n",
    "        if(yp == new_Y[i]):\n",
    "            count = count +1\n",
    "\n",
    "    return count / Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9890221031827218\n",
      "0.9782624651433336\n",
      "0.9677167485494828\n",
      "0.9579615519118195\n",
      "0.9491381273528314\n",
      "0.9410869845226995\n",
      "0.9342676213580026\n",
      "0.9289865942811809\n",
      "0.924733766327447\n",
      "0.9207930376285539\n",
      "0.9176052182989474\n",
      "0.9150061227342403\n",
      "0.9127306958441642\n",
      "0.9106339820967041\n",
      "0.9086672371618023\n",
      "0.9072234402378486\n",
      "0.9060034917115621\n",
      "0.9049501609175247\n",
      "0.9039753059258787\n",
      "0.9031442511495736\n",
      "0.9024132607423988\n",
      "0.901755469192951\n",
      "0.9011911152917711\n",
      "0.9007385135045076\n",
      "0.9003294903667488\n",
      "0.8999286041434071\n",
      "0.8995561516487622\n",
      "0.8992163806559244\n",
      "0.8988852040562179\n",
      "0.8986035718840285\n",
      "0.8983714387965507\n",
      "0.8981439244945001\n",
      "0.8979209371555357\n",
      "0.8977023867819813\n",
      "0.8974881851645755\n",
      "0.8972842691892843\n",
      "0.8971042976060529\n",
      "0.8969279074340727\n",
      "0.8967550274693098\n",
      "0.8965855879227244\n",
      "0.8964230887868535\n",
      "0.8962687132650586\n",
      "0.8961174099137946\n",
      "0.8959691176523545\n",
      "0.8958248598294228\n",
      "0.8956825395932574\n",
      "0.8955429023931997\n",
      "0.8954060443280517\n",
      "0.8952719101405698\n",
      "0.895140445671641\n",
      "0.8950115978384636\n",
      "0.8948853146131645\n",
      "0.8947615450018382\n",
      "0.89464114013426\n",
      "0.8945225609674532\n",
      "0.8944060124907276\n",
      "0.8942917840563412\n",
      "0.8941798295308395\n",
      "0.894070103697623\n",
      "0.8939625622387308\n",
      "0.8938571617169865\n",
      "0.8937538595584973\n",
      "0.8936533487612537\n",
      "0.8935545991717738\n",
      "0.8934573212267006\n",
      "0.8933619801139179\n",
      "0.8932685373160832\n",
      "0.8931769550813856\n",
      "0.8930871964083366\n",
      "0.89300592384324\n",
      "0.892932957905385\n",
      "0.8928626157433741\n",
      "0.8927918905008427\n",
      "0.8927225737468021\n",
      "0.8926546374676936\n",
      "0.892589639862166\n",
      "0.892525173137816\n",
      "0.8924635018345424\n",
      "0.8924044816880781\n",
      "0.89235094577232\n",
      "0.8922939443062335\n",
      "0.8922422739592601\n",
      "0.8921952551476938\n",
      "0.8921518346895931\n",
      "0.8921057302185628\n",
      "0.8920640190081671\n",
      "0.892023249061668\n",
      "0.8919862583352678\n",
      "0.891952095199026\n",
      "0.8919157186028427\n",
      "0.8918812454146479\n",
      "0.8918488025191823\n",
      "0.8918164786536819\n",
      "0.8917862450006804\n",
      "0.8917547598676826\n",
      "0.8917249483636263\n",
      "0.8916968238333741\n",
      "0.8916662240036366\n",
      "0.8916390455322377\n",
      "0.8916123788887478\n",
      "0.891583479965725\n",
      "0.8915594114339663\n",
      "0.891537472514543\n",
      "0.8915159305518832\n",
      "0.8914952905260033\n",
      "0.8914750114064655\n",
      "0.8914561113486099\n",
      "0.8914348646039433\n",
      "0.8914193486541379\n",
      "0.8913984457339704\n",
      "0.8913804971344645\n",
      "0.8913641813869407\n",
      "0.8913458263275404\n",
      "0.8913279056668921\n",
      "0.8913118531601387\n",
      "0.8912941774153592\n",
      "0.8912813386407135\n",
      "0.8912628976547459\n",
      "0.8912489603987057\n",
      "0.8912323735575467\n",
      "0.8912186776001474\n",
      "0.8912030686804652\n",
      "0.891190422970977\n",
      "0.8911758076499161\n",
      "0.8911607578478455\n",
      "0.8911479480989674\n",
      "0.8911360629971261\n",
      "0.8911213302581177\n",
      "0.8911104805068651\n",
      "0.8910968862552653\n",
      "0.8910865020574399\n",
      "0.8910732832219155\n",
      "0.891059981287396\n",
      "0.8910519304342099\n",
      "0.8910379937559685\n",
      "0.8910267774220645\n",
      "0.8910184176047375\n",
      "0.8910065674020263\n",
      "0.8909980787566967\n",
      "0.8909864373820593\n",
      "0.8909751500335606\n",
      "0.8909680314234172\n",
      "0.8909557697907744\n",
      "0.8909469008181342\n",
      "0.8909406085437603\n",
      "0.8909273687771044\n",
      "0.8909221635070734\n",
      "0.8909125378647548\n",
      "0.8909029805330622\n",
      "0.8908966805775862\n",
      "0.8908863127201461\n",
      "0.8908810392037758\n",
      "0.8908717735880214\n",
      "0.8908615857664419\n",
      "0.8908606892116782\n",
      "0.8908483783958299\n",
      "0.8908416572178401\n",
      "0.890836280937643\n",
      "0.89082740901128\n",
      "0.8908229423122062\n",
      "0.8908146572070528\n",
      "0.8908087080190299\n",
      "0.89080310096146\n",
      "0.8907944213832725\n",
      "0.8907894522430103\n",
      "0.8907849729207294\n",
      "0.8907772426183892\n",
      "0.8907736935889644\n",
      "0.8907664105188828\n",
      "0.8907609339188927\n",
      "0.8907563520428216\n",
      "0.8907513833226959\n",
      "0.8907448066150259\n",
      "0.8907410311833207\n",
      "0.8907346278089733\n",
      "175\n",
      "0.7132216014897579\n",
      "0.7186147186147186\n"
     ]
    }
   ],
   "source": [
    "l = 10  # lambda\n",
    "w_result = svm(X_train, Y_train, 0.001, l,3000)\n",
    "print(svm_accuracy(w_result, X_train, Y_train))\n",
    "print(svm_accuracy(w_result, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X, k):\n",
    "    mean = np.mean(X, axis = 0)   # the mean value of X\n",
    "    std = np.std(X, axis=0)       # the standard deviation along axis 0\n",
    "    X_std = (X - mean) / std      # standardized data\n",
    "    cov_mat = np.cov(X_std.T)     # calculate the covariance matrix\n",
    "\n",
    "    values, vectors = np.linalg.eig(cov_mat)   # Eigendecomposition of covariance matrix\n",
    "\n",
    "    # Make a list of (eigenvalue, eigenvector) tuples\n",
    "    eig_pairs = [(np.abs(values[i]), vectors[i,:]) for i in range(len(values))]\n",
    "\n",
    "    # Sort the tuples from the highest to the lowest based on eigenvalues magnitude\n",
    "    eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Store the soted eigenvalues and their corresponding eigenvectors\n",
    "    vecs_sorted = np.array([x[1] for x in eig_pairs])\n",
    "\n",
    "    W = vecs_sorted[:k, :]   # Projection matrix with the top k eigenvectors selected\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 140)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = pca(X_train, 40)\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "svm() missing 1 required positional argument: 'max_iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [201], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X_proj \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mdot(W\u001b[39m.\u001b[39mT)             \u001b[39m# transform X via W to obtain a k-dimensional feature subspace.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m w \u001b[39m=\u001b[39m svm(X_proj, Y_train, \u001b[39m0.0001\u001b[39;49m, l)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(svm_accuracy(w, X_proj, Y_train))\n",
      "\u001b[0;31mTypeError\u001b[0m: svm() missing 1 required positional argument: 'max_iter'"
     ]
    }
   ],
   "source": [
    "X_proj = X_train.dot(W.T)             # transform X via W to obtain a k-dimensional feature subspace.\n",
    "w = svm(X_proj, Y_train, 0.0001, l)\n",
    "print(svm_accuracy(w, X_proj, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "X_proj = X_test.dot(W.T)       # transform X via W to obtain a k-dimensional feature subspace.\n",
    "print(svm_accuracy(w, X_proj, Y_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
