{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "J1grKKjV-nzO",
    "outputId": "2b07549d-7ba6-4e10-dd9d-b232e58d6d35"
   },
   "outputs": [],
   "source": [
    "# pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "0CQf65BS-nzT",
    "outputId": "37de0002-4906-4e99-a47f-609be2f2fade"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPlease install this specific version of resampy for librosa to work without errors.\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Please install this specific version of resampy for librosa to work without errors.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "7FE1qM7n-nzU",
    "outputId": "02c7b706-8c9c-42b4-ed25-b98f7cd915de"
   },
   "outputs": [],
   "source": [
    "# pip install resampy==0.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "_hwFIUlFzTYw",
    "outputId": "9419a67b-5c1d-47e0-a7f5-ec9b9cad5bca"
   },
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "GWrZdqrp2E98"
   },
   "outputs": [],
   "source": [
    "emotions ={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrgQMSEU-nzZ"
   },
   "source": [
    "### Data for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "vSe0sBT12HgO"
   },
   "outputs": [],
   "source": [
    "def load_extract_features(data_path):\n",
    "\n",
    "    '''\n",
    "    load_extract_features() is a function that is used to load all the audio files one at a time, compute their features and return the features as well as the target values.\n",
    "\n",
    "    There are around 8-10 audio files which are corrupted. We hardcode zero values for such files in order to maintain consistency.\n",
    "\n",
    "    ['calm', 'happy'] emotion data is categorized into 'positive' and  ['angry', 'fearful'] into 'negative'\n",
    "\n",
    "    Returns:\n",
    "    1. Features\n",
    "    2. Binary Target Values\n",
    "    '''\n",
    "    final_features,target_emotions, binary_label = [],[], []\n",
    "    count = 0\n",
    "    \n",
    "    for i in glob.glob(data_path + \"/Actor_*/*.wav\"): #Loop to read every file.\n",
    "        \n",
    "        name = os.path.basename(i)\n",
    "        #We split the name of the file to understand the emotion associated with the file.\n",
    "        split = name.split(\"-\")\n",
    "        #We know that the third identifier is associated with the emotion of the audio file. Hence, we use [2] as it represents the third identifier.\n",
    "        emotion = emotions[split[2]]\n",
    "\n",
    "        #Below is the code to categorize the emotions into two classes to make this a binary problem.\n",
    "        if emotion in ['calm', 'happy']:\n",
    "            binary_label.append(0)\n",
    "        elif emotion in ['angry', 'fearful']:\n",
    "            binary_label.append(1)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        with soundfile.SoundFile(i) as audio:\n",
    "            waveform = audio.read(dtype=\"float32\")\n",
    "            sr = audio.samplerate\n",
    "            \n",
    "            #Below is the code to extract the Mel spectrogram features\n",
    "            #128 is the standard for machine learning applications using Mel spectrograms\n",
    "            m_feature = librosa.feature.melspectrogram(y=waveform, sr=sr, n_mels=128, fmax=sr / 2.0).T\n",
    "            melspectrogram = np.mean(m_feature,axis=0)\n",
    "            if melspectrogram.shape != (128,):\n",
    "                melspectrogram = np.zeros(128)\n",
    "            \n",
    "            #Below is the code to extract the chromagram features\n",
    "            stft_wave = librosa.stft(waveform)\n",
    "            stft = np.abs(stft_wave)\n",
    "            c_feature = librosa.feature.chroma_stft(S=stft, sr=sr).T\n",
    "            chromagram = np.mean(c_feature,axis=0)\n",
    "            \n",
    "            #12 is the number of pitch classes\n",
    "            if chromagram.shape != (12,):\n",
    "                chromagram = np.zeros(12)\n",
    "                \n",
    "            features=np.array([])\n",
    "            features=np.hstack((chromagram, melspectrogram))\n",
    "        \n",
    "            final_features.append(features)\n",
    "            target_emotions.append(emotion)\n",
    "            \n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                print(\"Processed Audio File Number: \", count)\n",
    "    \n",
    "    #We return the features and the binary target values.\n",
    "    return np.array(final_features), np.array(binary_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "aER6S-_k2a9H"
   },
   "outputs": [],
   "source": [
    "#Please change the path below to the path of the folder saved in your computer.\n",
    "# data_path = './Audio_Speech_Actors_01-24'\n",
    "# X, binary_label = load_extract_features(data_path)\n",
    "# print(X.shape)\n",
    "# print(binary_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('matrix.txt', X, delimiter = ',')  \n",
    "# np.savetxt('binary_label.txt',binary_label,delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 140)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "X = np.loadtxt(open(\"matrix.txt\",\"rb\"), delimiter=\",\", skiprows=0)\n",
    "binary_label = np.loadtxt(open(\"binary_label.txt\",\"rb\"), delimiter=\",\", skiprows=0)\n",
    "\n",
    "print(X.shape) #should be (768,140)\n",
    "print(binary_label.shape) # should be (768,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, binary_label, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(W, X, Y, l):\n",
    "    # calculate hinge loss\n",
    "    n_s = X.shape[0]\n",
    "    distances = 1 - Y * (np.dot(X, W))\n",
    "    distances[distances < 0] = 0  # equivalent to max(0, distance)\n",
    "    hinge_loss =  (np.sum(distances) / n_s)\n",
    "    # calculate cost\n",
    "    cost = l / 2 * np.dot(W, W) + hinge_loss \n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(W, X, Y,l):\n",
    "\n",
    "    distance = 1 - (Y * np.dot(X, W))\n",
    "    dw = np.zeros(len(W))\n",
    "\n",
    "    for ind, d in enumerate(distance):\n",
    "        if (ind == W.shape[0]):\n",
    "            if max(0, d) != 0:\n",
    "                di =  - ( Y[ind] * X[ind])\n",
    "        else:\n",
    "            if max(0, d) == 0:\n",
    "                di = l*W\n",
    "            else:\n",
    "                di = l*W - ( Y[ind] * X[ind])\n",
    "        dw += di\n",
    "\n",
    "    dw = dw/len(Y)  # average\n",
    "\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(X, Y, step, l,max_iter):\n",
    "    X_bia = np.c_[X, np.ones(X.shape[0])]   # Pad 1's for the bias term\n",
    "    new_Y = np.ones((Y.shape[0]))\n",
    "\n",
    "    for i in range (Y.shape[0]):\n",
    "        if Y[i] == 0:\n",
    "            new_Y[i] = -1\n",
    "\n",
    "    w = np.zeros(X_bia.shape[1])\n",
    "    count = 0\n",
    "    cost = compute_cost(w, X_bia, new_Y, l)\n",
    "    for i in range(max_iter):\n",
    "        grad = calculate_gradient(w, X_bia, new_Y, l)\n",
    "        new_w = w - step * grad\n",
    "        new_cost = compute_cost(new_w, X_bia, new_Y, l)\n",
    "\n",
    "        if (new_cost<cost):\n",
    "            w = new_w\n",
    "            cost = new_cost\n",
    "            count= count +1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_accuracy(W,X,Y):\n",
    "\n",
    "    X_bia = np.c_[X, np.ones(X.shape[0])]   # Pad 1's for the bias term\n",
    "    new_Y = np.ones((Y.shape[0]))\n",
    "\n",
    "    for i in range (Y.shape[0]):\n",
    "        if Y[i] == 0:\n",
    "            new_Y[i] = -1\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        yp = np.sign(np.dot(W, X_bia[i])) #model\n",
    "        if(yp == new_Y[i]):\n",
    "            count = count +1\n",
    "\n",
    "    return count / Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy when applied to the training subset: 0.7188081936685289\n",
      "The accuracy when applied to the testing subset: 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "l = 1  # lambda\n",
    "w_result = svm(X_train, Y_train, 0.00001, l, 5000)\n",
    "print(\"The accuracy when applied to the training subset: \" + str(svm_accuracy(w_result, X_train, Y_train)))\n",
    "print(\"The accuracy when applied to the testing subset: \" + str(svm_accuracy(w_result, X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X, k):\n",
    "    mean = np.mean(X, axis = 0)   # the mean value of X\n",
    "    std = np.std(X, axis=0)       # the standard deviation along axis 0\n",
    "    X_std = (X - mean) / std      # standardized data\n",
    "    cov_mat = np.cov(X_std.T)     # calculate the covariance matrix\n",
    "\n",
    "    values, vectors = np.linalg.eig(cov_mat)   # Eigendecomposition of covariance matrix\n",
    "\n",
    "    # Make a list of (eigenvalue, eigenvector) tuples\n",
    "    eig_pairs = [(np.abs(values[i]), vectors[i,:]) for i in range(len(values))]\n",
    "\n",
    "    # Sort the tuples from the highest to the lowest based on eigenvalues magnitude\n",
    "    eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Store the soted eigenvalues and their corresponding eigenvectors\n",
    "    vecs_sorted = np.array([x[1] for x in eig_pairs])\n",
    "\n",
    "    W = vecs_sorted[:k, :]   # Projection matrix with the top k eigenvectors selected\n",
    "\n",
    "    return mean, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, W = pca(X_train, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy when applied to the training subset: 0.6350093109869647\n",
      "The accuracy when applied to the testing subset: 0.6926406926406926\n"
     ]
    }
   ],
   "source": [
    "X_proj = (X_train - mean).dot(W.T)           # transform X via W to obtain a k-dimensional feature subspace.\n",
    "X_proj_test = (X_test - mean).dot(W.T)       # transform X via W to obtain a k-dimensional feature subspace.\n",
    "w = svm(X_proj, Y_train, 0.0001, l, 5000)    # Train the resulted data with svm\n",
    "\n",
    "print(\"The accuracy when applied to the training subset: \" + str(svm_accuracy(w, X_proj, Y_train)))\n",
    "print(\"The accuracy when applied to the testing subset: \" + str(svm_accuracy(w, X_proj_test, Y_test)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a389e7b46637685677c3035058cdcb08f230090c2d970bdc328fa871b645c8ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
